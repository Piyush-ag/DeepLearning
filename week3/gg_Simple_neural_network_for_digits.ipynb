{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5S649BJJQgWN"
      },
      "source": [
        "# Simple Fully Connected Neural Network Example\n",
        "\n",
        "In this tutorial, we will implemnet a simple fully connected neural network with TensorFlow.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VZisChDOXkC"
      },
      "source": [
        "![GettingStarted](https://mooc-styleguide.s3.amazonaws.com/MOOC-Styles/Active+Learning+Headers/Links/ALH_GettingStarted.png)\n",
        "\n",
        "\n",
        "#[Step 1] **READ**: Simple Digit Recognition with Neural Network\n",
        "\n",
        "In the prescriptions, doctors have different hand writing styles. When we have the hand written digit pictures, it might be hard to recognize someone's handwriting on the first sight. What would be a better way to scan the pictures and extract key information? Can we apply AI to simplify the process?\n",
        "\n",
        "##  AI-Driven Solution: Simple Fully Connected Neural Network\n",
        "\n",
        "By building a simple neural network model, we could ask AI to help us capture the features in each picture and training our model to recognize the digits.\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEtb8QDzQgWT"
      },
      "source": [
        "## Simple Neural Network Overview\n",
        "![picture](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MmrWSRkddKWmY7uAnp6DgQ.jpeg)\n",
        "\n",
        "\n",
        "\n",
        "### MNIST Dataset Overview\n",
        "\n",
        "This example is using MNIST handwritten digits. The dataset contains 60,000 examples for training and 10,000 examples for testing. The digits have been size-normalized and centered in a fixed-size image (28x28 pixels) with values from 0 to 1. For simplicity, each image has been flattened and converted to a 1-D numpy array of 784 features (28*28).\n",
        "\n",
        "![MNIST Dataset](https://miro.medium.com/max/530/1*VAjYygFUinnygIx9eVCrQQ.png)\n",
        "\n",
        "More info: http://yann.lecun.com/exdb/mnist/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyGigtEvQgWV"
      },
      "source": [
        "#[Step 2] **RUN**: Setting Up the Colab Environment\n",
        "\n",
        "**Importing Packages**\n",
        "\n",
        "Python packages enable different functions, providing easy ways of manipulating data and building models. As a first step, we 'import' packages to set up our environment in a way that allows us to take advantage of different capabilities.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RrkLi8ZRQgWY"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/piyush/workspace/projects/DeepLearning/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# use TF2\n",
        "# %tensorflow_version 2.x\n",
        "\n",
        "import numpy\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras import backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "K.set_image_data_format('channels_first')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyOBmmaBQgWc"
      },
      "source": [
        "**Set the seed**\n",
        "<br>\n",
        "Setting the seed will keep the starting number used to generate a sequence of random numbers the same – it ensures that you get the same result if you start with that same seed each time you run the same process. Using a constant seed value will give us reproducibility of results.\n",
        "\n",
        "<br>\n",
        "\n",
        "The randomization part is the initialization on the model parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1YWQdnrKQgWd"
      },
      "outputs": [],
      "source": [
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "tf.keras.utils.set_random_seed(seed)\n",
        "tf.config.experimental.enable_op_determinism()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxmMKen8QgWg"
      },
      "source": [
        "\n",
        "**Loading Dataset**\n",
        "\n",
        "\n",
        "The MNINST train and test datasets are splited by the authors at the very beginning.\n",
        "\n",
        "It can enable a consistent metric for evaluating different classification models.\n",
        "\n",
        "<br>\n",
        "\n",
        "For more information, please see [MINST Dataset](http://yann.lecun.com/exdb/mnist/)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HGWAom6DTkDx"
      },
      "outputs": [],
      "source": [
        "# load data\n",
        "(X_train_raw, y_train_raw), (X_test_raw, y_test_raw) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXRYiSQRTtvl"
      },
      "source": [
        "# [Step 3] MNIST Data Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkWYaq4fabpm"
      },
      "source": [
        "## X Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JMiKR_AGTwS3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "In the Train dataset, there are 60,000 images (data points). Each image (data point) is a 28 * 28 matrix.\n",
            "(60000, 28, 28)\n",
            "\n",
            "\n",
            "In the Test dataset, there are 10,000 images (data points). Each image (data point) is a 28 * 28 matrix.\n",
            "(10000, 28, 28)\n"
          ]
        }
      ],
      "source": [
        "print('In the Train dataset, there are 60,000 images (data points). Each image (data point) is a 28 * 28 matrix.')\n",
        "print(X_train_raw.shape)\n",
        "print('\\n')\n",
        "\n",
        "\n",
        "print('In the Test dataset, there are 10,000 images (data points). Each image (data point) is a 28 * 28 matrix.')\n",
        "print(X_test_raw.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4LETU8ePqmI1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(60000,)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train_raw.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "W1h2pWmJXVzV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  42, 118, 219, 166, 118, 118,   6,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 103, 242, 254, 254, 254, 254, 254,  66,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 232, 254, 254, 254, 254, 254, 238,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 104, 244, 254, 224, 254, 254, 254, 141,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 207, 254, 210, 254, 254, 254,  34,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  84, 206, 254, 254, 254, 254,  41,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 209, 254, 254, 254, 171,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  91, 137, 253, 254, 254, 254, 112,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  40, 214, 250, 254, 254, 254, 254, 254,  34,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  81, 247, 254, 254, 254, 254, 254, 254, 146,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 110, 246, 254, 254, 254, 254, 254, 171,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  73,  89,  89,  93, 240, 254, 171,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1, 128, 254, 219,  31,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   7, 254, 254, 214,  28,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 138, 254, 254, 116,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,  19, 177,  90,   0,   0,   0,   0,   0,  25, 240, 254, 254,  34,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0, 164, 254, 215,  63,  36,   0,  51,  89, 206, 254, 254, 139,   8,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,  57, 197, 254, 254, 222, 180, 241, 254, 254, 253, 213,  11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0, 140, 105, 254, 254, 254, 254, 254, 254, 236,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   7, 117, 117, 165, 254, 254, 239,  50,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], dtype=uint8)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "def pretty_print(np_array):\n",
        "    array_str = np.array_repr(np_array).replace('],\\n', '**').replace('\\n       ', '').replace('**', '],\\n')#.replace(', ', '')\n",
        "    print(array_str)\n",
        "\n",
        "sample_idx = 10\n",
        "X_sample = X_train_raw[sample_idx]\n",
        "pretty_print(X_sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jlea5sI3VAOS"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x1260104f0>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# print(plt.cm.cmap_d.keys())\n",
        "plt.imshow(X_sample, cmap = plt.cm.binary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHwc4LcSeW1H"
      },
      "source": [
        "# [Step 4] Data Preprocession\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAeEYt6uebXV"
      },
      "source": [
        "## X: Normalize the Data to [0,1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B71piImpTiW9"
      },
      "source": [
        "\n",
        "\n",
        "<br>\n",
        "In the case of RGB, the first dimension pixels would be 3 for the red, green and blue components and it would be like having 3 image inputs for every color image. In the case of MNIST where the pixel values are gray scale, the pixel dimension is set to 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6osjFpXyQgWj"
      },
      "source": [
        "Then we normalize the pixel values to the range 0 and 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3K-vaaMpbIz"
      },
      "source": [
        "**Why normalize?**\n",
        "\n",
        "Neural networks process inputs using small weight values, and inputs with large integer values can disrupt or slow down the learning process. As such it is good practice to normalize the pixel values so that each pixel value has a value between 0 and 1\n",
        "\n",
        "[Read more about normalization here](https://machinelearningmastery.com/how-to-manually-scale-image-pixel-data-for-deep-learning/#:~:text=Normalize%20Pixel%20Values,-For%20most%20image&text=Neural%20networks%20process%20inputs%20using,value%20between%200%20and%201.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_zBG24odQgWk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ]
        }
      ],
      "source": [
        "# normalize inputs from 0-255 to 0-1\n",
        "X_train = X_train_raw / 255\n",
        "X_test  = X_test_raw  / 255\n",
        "\n",
        "\n",
        "print(X_train.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8XApf8T2QMG"
      },
      "source": [
        "## y Transformation\n",
        "\n",
        "We don't have specific transformation for `y` data\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMk5DKIs6ziB"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Yid7xpsy2Pev"
      },
      "outputs": [],
      "source": [
        "y_train = y_train_raw\n",
        "y_test  = y_test_raw"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mXjqf1NQgWn"
      },
      "source": [
        "#[Step 5] **RUN**: Setting Up the Neural Network Architecture\n",
        "\n",
        "**Design the neural network architecture**\n",
        "\n",
        "1. First, we are going to create the model framework. It is like the basic structure of a house without furniture and room layouts\n",
        "2. Next we will add the flatten layer which we can input an image. This layer will flatten the image to a vector so we can pass it in to the neural network. Each pixel of the image will become an individual input that feeds in the next hidden layer\n",
        "3. The next layer is a fully connected with 128 neurons. Because the neurals are all close to each other, we cal it the \"dense\" layer . Each neuron on this layer are fully connected to the last layer. It takes the input from last layer, aggregate them and run them through a \"Relu\" function. \"Relu\" is an activation function which will transform the aggregated result in each neuron\n",
        "4. The next layer is our output layer. The output layer has 10 neurons because we have 10 different digits in this classification problems. We feed the results from last layer to a softmax activation function to output probability-like predictions for each class. The digits with the highest probability is what the algorithm thought the digit to be\n",
        "5. The model is trained using categorical cross entropy loss function and the ADAM optimizer for gradient descent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqUITJeDkzM5"
      },
      "source": [
        "**Now we are going to define a function to help us create a base model with the layers we dicussed**\n",
        "\n",
        "Quick note: we use the **\"def\"** keyword in python to define a function. By defining a function, it increases the reusability and save us time when we want to create the same model. So that we don't have to write out all the layers every time.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Y6zTEc6TQgWo"
      },
      "outputs": [],
      "source": [
        "def baseline_model():\n",
        "    # Create a model\n",
        "    # weights and bias are randomly initlized used \n",
        "    model = Sequential()\n",
        "    # Add different layers to your model\n",
        "    model.add(Flatten(input_shape=(28, 28)))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dense(10, activation='sigmoid'))\n",
        "    # Compile model\n",
        "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4X85NGMBQgWr"
      },
      "source": [
        "---\n",
        "![APPLY](https://mooc-styleguide.s3.amazonaws.com/MOOC-Styles/Active+Learning+Headers/Links/ALH_Apply.png)\n",
        "#[Step 6] **APPLY**: Train Fully Connected Neural Network for Digit Recognition on Train Set\n",
        "\n",
        "With our environment set up and data loaded, we can now train, test, and evaluate our model to recognize the 10 different digits. To do this, we will use the train set and test set we created in step 2 to train our model.\n",
        "Running the example, the accuracy on the training and validation test is printed each epoch and at the end of the classification error rate is printed.\n",
        "\n",
        "\n",
        "**Train the model**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ubfFl-TjySdi"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/piyush/workspace/projects/DeepLearning/.venv/lib/python3.9/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">25,120</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">330</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m25,120\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m1,056\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m330\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">26,506</span> (103.54 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m26,506\u001b[0m (103.54 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">26,506</span> (103.54 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m26,506\u001b[0m (103.54 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Call the function we defined earlier to create the model\n",
        "# The trainable parameters within the new model are set by the default initialization methods from Keras.\n",
        "model = baseline_model()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "bjwjRkvtQgWs"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 610us/step - accuracy: 0.7057 - loss: 1.0226\n",
            "Epoch 2/5\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626us/step - accuracy: 0.9265 - loss: 0.2596\n",
            "Epoch 3/5\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - accuracy: 0.9409 - loss: 0.2046\n",
            "Epoch 4/5\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593us/step - accuracy: 0.9511 - loss: 0.1705\n",
            "Epoch 5/5\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - accuracy: 0.9575 - loss: 0.1475\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x1262b7e20>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train the model using the picture stored in X_train and the corresponding labels stored in Y_train\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=200, verbose=1) #verbose =1 will show the progress bar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hobO9fxIZA4D"
      },
      "source": [
        "# [Step 7] Evaluate the Model Performance on the Test Set\n",
        "\n",
        "<br>\n",
        "X_test include the new digit images the model has never seen\n",
        "<br>\n",
        "y_test include the correct labels of the test set\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "pwsRIh6iGCkY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Simple NN Accuracy: 95.79%\n",
            "Simple NN Error:    4.21%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-02-12 15:30:34.774560: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n",
            "2025-02-12 15:30:34.774833: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n"
          ]
        }
      ],
      "source": [
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0) # scores has [loss] and [accuracy]\n",
        "#Print out the error rate\n",
        "print('Simple NN Accuracy: %.2f%%'% (scores[1]*100))\n",
        "print(\"Simple NN Error:    %.2f%%\"% (100-scores[1]*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxPlt5dmqOoz"
      },
      "source": [
        "# ** By now, the job is done. However, it is always good to inspect results carefully. **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEwzzomkbbHH"
      },
      "source": [
        "#[Step 8] Define a function to display the image and the predicted label to check model performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "paWr2KkdhQa2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309us/step\n"
          ]
        }
      ],
      "source": [
        "# Make predictions using the model\n",
        "predictions = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "qpP6T0m8QgWx"
      },
      "outputs": [],
      "source": [
        "def plot_image(i, predictions_array, true_label, img):\n",
        "    predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n",
        "    plt.grid(False)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "\n",
        "    plt.imshow(img, cmap=plt.cm.binary)\n",
        "\n",
        "    predicted_label = numpy.argmax(predictions_array)\n",
        "    # if the algorithm makes the right prediction, it will show a blue text, otherwise show in red text\n",
        "    if predicted_label == true_label:\n",
        "      color = 'blue'\n",
        "    else:\n",
        "      color = 'red'\n",
        "\n",
        "    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
        "                                  100*numpy.max(predictions_array),\n",
        "                                  class_names[true_label]),\n",
        "                                  color=color)\n",
        "\n",
        "def plot_value_array(i, predictions_array, true_label):\n",
        "    predictions_array, true_label = predictions_array[i], true_label[i]\n",
        "    plt.grid(False)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
        "    plt.ylim([0, 1])\n",
        "    predicted_label = numpy.argmax(predictions_array)\n",
        "\n",
        "    thisplot[predicted_label].set_color('red')\n",
        "    thisplot[true_label].set_color('blue')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "MHJtNrO5QgW3"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load the data and create a list of class names\n",
        "class_names = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
        "\n",
        "# Let's examine the 1st and the 19th image to check for accuracy\n",
        "image_sample_idxes = [0, 18]\n",
        "for i in image_sample_idxes:\n",
        "    plt.figure(figsize=(6, 3))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plot_image(i, predictions, y_test_raw, X_test_raw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "RGCiFTZD3qBA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[8, 33, 195, 233, 247, 259, 320, 321, 340, 362]\n",
            "421\n"
          ]
        }
      ],
      "source": [
        "# Time to check the ones that the algorithm missed\n",
        "\n",
        "\n",
        "def check_wrong(i, predictions_array, true_label, img):\n",
        "    predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n",
        "\n",
        "    predicted_label = numpy.argmax(predictions_array)\n",
        "    if predicted_label == true_label:\n",
        "        return False\n",
        "    else:\n",
        "        return True\n",
        "\n",
        "\n",
        "wrong_prediction_images_index = []\n",
        "for i in range(len(predictions)):\n",
        "    if check_wrong(i, predictions, y_test_raw, X_test_raw) == True:\n",
        "        wrong_prediction_images_index.append(i)\n",
        "\n",
        "print(wrong_prediction_images_index[:10])\n",
        "print(len(wrong_prediction_images_index))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "uKfccECQQgW6"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def plot_wrong(i, predictions_array, true_label, img):\n",
        "    predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n",
        "\n",
        "    predicted_label = numpy.argmax(predictions_array)\n",
        "    if predicted_label == true_label:\n",
        "        pass\n",
        "    else:\n",
        "        plt.figure(figsize=(6,3))\n",
        "        plt.subplot(1,2,1)\n",
        "        plot_image(i, predictions, y_test_raw, X_test_raw)\n",
        "\n",
        "# We are going to check the first 100 images to see which one the model predicted wrong\n",
        "\n",
        "top_k = 3\n",
        "for i in wrong_prediction_images_index[:top_k]:\n",
        "    plot_wrong(i, predictions, y_test_raw, X_test_raw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YTaG87vF0FhI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46jbVZVNcaqX"
      },
      "source": [
        "---\n",
        "![Learn](https://mooc-styleguide.s3.amazonaws.com/MOOC-Styles/Active+Learning+Headers/Links/ALH_Learn.png)\n",
        "\n",
        "\n",
        "# [Step 9] **READ**: Conclusions\n",
        "This is a relatively simple and easy to understand model for us to get a view of how powerful neural network is in classification problems like digit recognition. We introduced the basic framework to create and train the fully connected neural network for our own use. We will get more in-depth into other image recognition topics later on in the course. But now let's discuss some of the questions you have.\n",
        "\n",
        "**What are some use cases to apply the image recognition algorithm in your everyday work?**\n",
        "\n",
        "\n",
        "*   \n",
        "*   \n",
        "\n",
        "\n",
        "\n",
        "**Q2...**\n",
        "\n",
        "\n",
        "*   \n",
        "*   \n",
        "\n",
        "**Q3...**\n",
        "*\n",
        "*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Nt_K0CvdijK"
      },
      "source": [
        "---\n",
        "![Practice](https://mooc-styleguide.s3.amazonaws.com/MOOC-Styles/Active+Learning+Headers/Links/ALH_Practice.png)\n",
        "# [Step 10] **LIVE SESSION PRACTICE**: Try Your Own Model!\n",
        "* Currently the model's accuracy is around 93%, not too bad. But can you think of ways to push the accuracy over 95%?\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "> (Hint) We trained the model with 5 epoches (i.e., going through the whole training dataset five times using backpropagation). Do you think the model has learned enough? Can we make it learn more by doing 10 epoches? Try it and see.\n",
        "\n",
        "Other tips:\n",
        "\n",
        "* redistribute the neurons between the two hidden layers\n",
        "* change the model structure by adding more layers\n",
        "* change the activation function to a fancier one called \"softmax\"\n",
        "\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "Once you have modified the model, you can run it by clicking \"Runtime/Restar and run all\". Do you see the accuracy increased as a result?\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "\n",
        "Have fun!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "347blP-sQgW9"
      },
      "outputs": [],
      "source": [
        "# Credit to Jason Brownlee\n",
        "# https://machinelearningmastery.com/handwritten-digit-recognition-using-convolutional-neural-networks-python-keras/"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "GyGigtEvQgWV",
        "QXRYiSQRTtvl",
        "RkWYaq4fabpm",
        "eHwc4LcSeW1H",
        "1mXjqf1NQgWn",
        "4X85NGMBQgWr",
        "hobO9fxIZA4D",
        "sEwzzomkbbHH",
        "7Nt_K0CvdijK"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
